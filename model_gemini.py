import os
import datetime
import time
import logging
import google.generativeai as genai
from dotenv import load_dotenv

# === –ó–ê–ì–†–£–ó–ö–ê .env ===
load_dotenv()

# === –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# === –ö–õ–ò–ï–ù–¢ GEMINI ===
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise EnvironmentError(
        "‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è GOOGLE_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. "
        "–î–æ–±–∞–≤—å –µ—ë –≤ .env –∏–ª–∏ –≤ Secrets –Ω–∞ Streamlit Cloud."
    )

genai.configure(api_key=GOOGLE_API_KEY)


class ModelProcessor:
    def __init__(self, model_name: str = "gemini-2.5-pro"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–ª—è Gemini.
        """
        self.model_name = model_name
        self.prompt_path = "system_prompt.txt"

        logger.info(f"üîß ModelProcessor (Gemini) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è...")
        logger.info(f"   –ú–æ–¥–µ–ª—å: {self.model_name}")

    def _load_system_instruction(self, is_chat: bool = False) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞."""
        if is_chat:
            return (
                "–¢—ã ‚Äî –ø—Å–∏—Ö–æ–ª–æ–≥-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ—Ñ–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏. "
                "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –ø–æ –¥–µ–ª—É. "
                "–ü–∏—à–∏ —Ç—ë–ø–ª—ã–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º —Ç–æ–Ω–æ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
                "–ë–ï–ó markdown-—Å–∏–º–≤–æ–ª–æ–≤."
            )

        if os.path.exists(self.prompt_path):
            try:
                with open(self.prompt_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    logger.info(f"‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞")
                    return content
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {self.prompt_path}: {e}")

        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç (—Ç–æ—Ç –∂–µ, —á—Ç–æ –±—ã–ª —É —Ç–µ–±—è)
        return """"–¢—ã ‚Äî –ø—Å–∏—Ö–æ–ª–æ–≥-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ—Ñ–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏.
                –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –ø–æ –¥–µ–ª—É.
                –ü–∏—à–∏ —Ç—ë–ø–ª—ã–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º —Ç–æ–Ω–æ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
                –ë–ï–ó markdown-—Å–∏–º–≤–æ–ª–æ–≤."""

    def _get_model(self, is_chat: bool = False):
        """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ —Å –Ω—É–∂–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏."""
        instruction = self._load_system_instruction(is_chat)
        return genai.GenerativeModel(
            model_name=self.model_name,
            system_instruction=instruction,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.9,
                "max_output_tokens": 10000 if not is_chat else 5000,
            }
        )

    def get_llm_response(self, user_data: str, is_chat: bool = False) -> str:
        """–û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–µ —Å—Ç—Ä–∏–º–∏–Ω–≥)."""
        logger.info(f"{'üí¨' if is_chat else 'üß†'} –ó–∞–ø—Ä–æ—Å –∫ Gemini...")

        try:
            model = self._get_model(is_chat)
            response = model.generate_content(user_data)

            if response.text:
                return response.text.strip()
            return "‚ùå –ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç."

        except Exception as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ Gemini API: {e}"
            logger.error(error_msg)
            return error_msg

    def get_streaming_response(self, user_data: str, is_chat: bool = False):
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç (–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä)."""
        logger.info("üì° –ù–∞—á–∏–Ω–∞–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Gemini")

        try:
            model = self._get_model(is_chat)
            # –í Gemini —Å—Ç—Ä–∏–º–∏–Ω–≥ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ stream=True
            response = model.generate_content(user_data, stream=True)

            for chunk in response:
                if chunk.text:
                    yield chunk.text

            logger.info("‚úÖ –°—Ç—Ä–∏–º–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}")
            yield f"[–û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}]"

    def save_report(self, text: str, user_name: str) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ (–ª–æ–≥–∏–∫–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)."""
        try:
            os.makedirs("reports", exist_ok=True)
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_name = "".join(c for c in user_name if c.isalnum() or c in (
                " ", "_", "-")).strip() or "user"
            filename = f"reports/{safe_name}_{timestamp}.txt"

            with open(filename, "w", encoding="utf-8-sig") as f:
                f.write(text)
            return filename
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç: {e}")
            return ""
