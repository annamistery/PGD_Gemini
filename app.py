import streamlit as st
import asyncio
import edge_tts
import os
import re
import time
from datetime import datetime

# Ð¢Ð²Ð¾Ð¸ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹...
from personality_preprocessor import PersonalityCupProcessor
from pgd_bot import PGD_Person_Mod
from chashka_points import chashka
from model_preprocessor_gemini import ModelProcessor

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
MODEL_ID = "gemini-2.5-pro"

if 'ai_manager' not in st.session_state:
    st.session_state.ai_manager = ModelProcessor(model_name=MODEL_ID)

# --- Ð’Ð¡ÐŸÐžÐœÐžÐ“ÐÐ¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¤Ð£ÐÐšÐ¦Ð˜Ð˜ ---


def clean_text_for_speech(text):
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ñ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð¹ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ¸ Ð½Ð° Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ…"""
    text = re.sub(r'[\*\#\_\-\>\<\`]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


async def generate_voice(text):
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð´Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ð¸Ð½Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°"""
    clean_text = clean_text_for_speech(text)
    
    # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° ÐºÑƒÑÐºÐ¸ Ð¿Ð¾ 3000 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² (Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ð´Ð»Ñ API)
    chunk_size = 3000
    chunks = [clean_text[i:i + chunk_size] for i in range(0, len(clean_text), chunk_size)]
    
    combined_filename = f"speech_{int(time.time())}.mp3"
    temp_files = []

    try:
        for i, chunk in enumerate(chunks):
            temp_name = f"temp_{i}_{combined_filename}"
            communicate = edge_tts.Communicate(chunk, "ru-RU-SvetlanaNeural")
            await communicate.save(temp_name)
            temp_files.append(temp_name)

        # Ð¡ÐºÐ»ÐµÐ¸Ð²Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹ (Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Ð¾Ð´Ð¸Ð½ Ñ„Ð°Ð¹Ð»)
        with open(combined_filename, "wb") as final_file:
            for temp_name in temp_files:
                with open(temp_name, "rb") as f:
                    final_file.write(f.read())
                os.remove(temp_name) # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ ÐºÑƒÑÐ¾Ðº

        # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¹
        for f in os.listdir():
            if f.startswith("speech_") and f.endswith(".mp3") and f != combined_filename:
                try: os.remove(f)
                except: pass

        return combined_filename
    except Exception as e:
        st.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ±Ð¾Ñ€ÐºÐµ Ð°ÑƒÐ´Ð¸Ð¾: {e}")
        return None

# --- Ð˜ÐÐ¢Ð•Ð Ð¤Ð•Ð™Ð¡ ---
st.set_page_config(page_title="PGD Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°", layout="wide")
st.title("ðŸŒŸ ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð¿ÑÐ¸Ñ…Ð¾Ð³ÐµÐ½ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°")

# Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
if 'ai_analysis' not in st.session_state:
    st.session_state.ai_analysis = None
if 'audio_file' not in st.session_state:
    st.session_state.audio_file = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

with st.sidebar:
    st.header("ðŸ“‹ Ð”Ð°Ð½Ð½Ñ‹Ðµ")
    name = st.text_input("Ð˜Ð¼Ñ")
    dob = st.date_input("Ð”Ð°Ñ‚Ð° Ñ€Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ", value=None,
                        min_value=datetime(1900, 1, 1), format="DD.MM.YYYY")
    gender = st.radio("ÐŸÐ¾Ð»", ('Ð–ÐµÐ½ÑÐºÐ¸Ð¹', 'ÐœÑƒÐ¶ÑÐºÐ¾Ð¹'), horizontal=True)
    process_btn = st.button("ðŸš€ Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð·", use_container_width=True)

# --- Ð›ÐžÐ“Ð˜ÐšÐ ---
if process_btn:
    if not dob or not name:
        st.error("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ!")
    else:
        progress_bar = st.progress(0)
        with st.status("ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°...", expanded=True) as status:
            # 1. Ð Ð°ÑÑ‡ÐµÑ‚Ñ‹
            date_str = dob.strftime('%d.%m.%Y')
            sex_char = 'Ð–' if gender == "Ð–ÐµÐ½ÑÐºÐ¸Ð¹" else 'Ðœ'
            person = PGD_Person_Mod(name, date_str, sex_char)
            main_data = person.calculate_points()
            progress_bar.progress(30)

            # 2. Ð˜Ð˜ ÐÐ½Ð°Ð»Ð¸Ð·
            data_with_context = f"Ð˜ÐœÐ¯: {name}\nÐ”ÐÐÐÐ«Ð•:\n{str(PersonalityCupProcessor(main_data, {}, gender=sex_char).result(chashka))}"
            ai_text = st.session_state.ai_manager.get_llm_response(
                data_with_context)
            st.session_state.ai_analysis = ai_text
            progress_bar.progress(70)

            # 3. Ð“Ð¾Ð»Ð¾Ñ (Ð’Ð°Ð¶Ð½Ð¾: ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² session_state)
            audio_path = asyncio.run(generate_voice(ai_text))
            st.session_state.audio_file = audio_path

            progress_bar.progress(100)
            status.update(label="âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!", state="complete")
        st.balloons()

# --- Ð’Ð«Ð’ÐžÐ” Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’ (ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð´Ð»Ñ Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ…) ---
if st.session_state.ai_analysis:
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ðŸ“„ ÐÐ½Ð°Ð»Ð¸Ð·")
        st.markdown(st.session_state.ai_analysis)

    with col2:
        st.subheader("ðŸ“¥ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹")

        # Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð±Ð»Ð¾Ðº Ð°ÑƒÐ´Ð¸Ð¾
        if st.session_state.audio_file and os.path.exists(st.session_state.audio_file):
            st.write("ðŸŽµ Ð¡Ð»ÑƒÑˆÐ°Ñ‚ÑŒ Ð¾Ñ‚Ñ‡ÐµÑ‚:")
            # ÐœÑ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ðµ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ð¸Ð· session_state
            st.audio(st.session_state.audio_file)

        # ÐšÐ½Ð¾Ð¿ÐºÐ° ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð¹ ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð´Ð»Ñ ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½Ð¾Ð²
        st.download_button(
            label="ðŸ’¾ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚",
            data=st.session_state.ai_analysis.encode('utf-8-sig'),
            file_name=f"PGD_{name}.txt",
            mime="text/plain",
            use_container_width=True
        )

    st.divider()

    # --- Ð§ÐÐ¢ ---
    st.subheader("ðŸ’¬ Ð”Ð¸Ð°Ð»Ð¾Ð³ Ñ Ð²Ð°ÑˆÐ¸Ð¼ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÐµÐ¼")
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    if query := st.chat_input("Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ..."):
        st.session_state.chat_history.append(
            {"role": "user", "content": query})
        with st.chat_message("user"):
            st.write(query)

        with st.chat_message("assistant"):
            with st.spinner("ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ..."):
                chat_context = f"Ð­Ñ‚Ð¾ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {name}: {st.session_state.ai_analysis}. ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ: {query}"
                response = st.session_state.ai_manager.get_llm_response(
                    chat_context, is_chat=True)
                st.write(response)
                st.session_state.chat_history.append(
                    {"role": "assistant", "content": response})



