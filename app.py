import streamlit as st
import asyncio
import edge_tts
import os
import re
import time
from datetime import datetime

# Ð¢Ð²Ð¾Ð¸ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹...
from personality_preprocessor import PersonalityCupProcessor
from pgd_bot import PGD_Person_Mod
from chashka_points import chashka
from model_preprocessor_gemini import ModelProcessor

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
MODEL_ID = "gemini-2.5-pro"

if 'ai_manager' not in st.session_state:
    st.session_state.ai_manager = ModelProcessor(model_name=MODEL_ID)

# --- Ð’Ð¡ÐŸÐžÐœÐžÐ“ÐÐ¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¤Ð£ÐÐšÐ¦Ð˜Ð˜ ---


def clean_text_for_speech(text):
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ñ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð¹ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ¸ Ð½Ð° Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ…"""
    text = re.sub(r'[\*\#\_\-\>\<\`]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


async def generate_voice(text):
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ñ Ð·Ð°Ñ‰Ð¸Ñ‚Ð¾Ð¹ Ð¾Ñ‚ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ… Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð¾Ð²"""
    clean_text = clean_text_for_speech(text)
    final_text = clean_text[:7000]

    if not final_text:
        return None

    # Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ… (Ð¾Ð½Ð¸ Ð¶ÐµÑÑ‚ÐºÐ¾ ÐºÑÑˆÐ¸Ñ€ÑƒÑŽÑ‚ Ð°ÑƒÐ´Ð¸Ð¾)
    filename = f"speech_{int(time.time())}.mp3"

    # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð², Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð·Ð°Ð±Ð¸Ð²Ð°Ñ‚ÑŒ Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð½Ð° Streamlit Cloud
    for f in os.listdir():
        if f.startswith("speech_") and f.endswith(".mp3"):
            try: os.remove(f)
            except: pass

    communicate = edge_tts.Communicate(final_text, "ru-RU-SvetlanaNeural")
    await communicate.save(filename)
    return filename

# --- Ð˜ÐÐ¢Ð•Ð Ð¤Ð•Ð™Ð¡ ---
st.set_page_config(page_title="PGD Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°", layout="wide")
st.title("ðŸŒŸ ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð¿ÑÐ¸Ñ…Ð¾Ð³ÐµÐ½ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°")

# Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
if 'ai_analysis' not in st.session_state:
    st.session_state.ai_analysis = None
if 'audio_file' not in st.session_state:
    st.session_state.audio_file = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

with st.sidebar:
    st.header("ðŸ“‹ Ð”Ð°Ð½Ð½Ñ‹Ðµ")
    name = st.text_input("Ð˜Ð¼Ñ")
    dob = st.date_input("Ð”Ð°Ñ‚Ð° Ñ€Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ", value=None,
                        min_value=datetime(1900, 1, 1), format="DD.MM.YYYY")
    gender = st.radio("ÐŸÐ¾Ð»", ('Ð–ÐµÐ½ÑÐºÐ¸Ð¹', 'ÐœÑƒÐ¶ÑÐºÐ¾Ð¹'), horizontal=True)
    process_btn = st.button("ðŸš€ Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð·", use_container_width=True)

# --- Ð›ÐžÐ“Ð˜ÐšÐ ---
if process_btn:
    if not dob or not name:
        st.error("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ!")
    else:
        progress_bar = st.progress(0)
        with st.status("ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°...", expanded=True) as status:
            # 1. Ð Ð°ÑÑ‡ÐµÑ‚Ñ‹
            date_str = dob.strftime('%d.%m.%Y')
            sex_char = 'Ð–' if gender == "Ð–ÐµÐ½ÑÐºÐ¸Ð¹" else 'Ðœ'
            person = PGD_Person_Mod(name, date_str, sex_char)
            main_data = person.calculate_points()
            progress_bar.progress(30)

            # 2. Ð˜Ð˜ ÐÐ½Ð°Ð»Ð¸Ð·
            data_with_context = f"Ð˜ÐœÐ¯: {name}\nÐ”ÐÐÐÐ«Ð•:\n{str(PersonalityCupProcessor(main_data, {}, gender=sex_char).result(chashka))}"
            ai_text = st.session_state.ai_manager.get_llm_response(
                data_with_context)
            st.session_state.ai_analysis = ai_text
            progress_bar.progress(70)

            # 3. Ð“Ð¾Ð»Ð¾Ñ (Ð’Ð°Ð¶Ð½Ð¾: ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² session_state)
            audio_path = asyncio.run(generate_voice(ai_text))
            st.session_state.audio_file = audio_path

            progress_bar.progress(100)
            status.update(label="âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!", state="complete")
        st.balloons()

# --- Ð’Ð«Ð’ÐžÐ” Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’ (ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð´Ð»Ñ Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ…) ---
if st.session_state.ai_analysis:
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ðŸ“„ ÐÐ½Ð°Ð»Ð¸Ð·")
        st.markdown(st.session_state.ai_analysis)

    with col2:
        st.subheader("ðŸ“¥ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹")

        # Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð±Ð»Ð¾Ðº Ð°ÑƒÐ´Ð¸Ð¾
        if st.session_state.audio_file and os.path.exists(st.session_state.audio_file):
            st.write("ðŸŽµ Ð¡Ð»ÑƒÑˆÐ°Ñ‚ÑŒ Ð¾Ñ‚Ñ‡ÐµÑ‚:")
            # ÐœÑ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ðµ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ð¸Ð· session_state
            st.audio(st.session_state.audio_file)

        # ÐšÐ½Ð¾Ð¿ÐºÐ° ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð¹ ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð´Ð»Ñ ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½Ð¾Ð²
        st.download_button(
            label="ðŸ’¾ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚",
            data=st.session_state.ai_analysis.encode('utf-8-sig'),
            file_name=f"PGD_{name}.txt",
            mime="text/plain",
            use_container_width=True
        )

      st.divider()

    # --- Ð§ÐÐ¢ ---
    st.subheader("ðŸ’¬ Ð”Ð¸Ð°Ð»Ð¾Ð³ Ñ Ð²Ð°ÑˆÐ¸Ð¼ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÐµÐ¼")
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    if query := st.chat_input("Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ..."):
        st.session_state.chat_history.append(
            {"role": "user", "content": query})
        with st.chat_message("user"):
            st.write(query)

        with st.chat_message("assistant"):
            with st.spinner("ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ..."):
                chat_context = f"Ð­Ñ‚Ð¾ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {name}: {st.session_state.ai_analysis}. ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ: {query}"
                response = st.session_state.ai_manager.get_llm_response(
                    chat_context, is_chat=True)
                st.write(response)
                st.session_state.chat_history.append(
                    {"role": "assistant", "content": response})
